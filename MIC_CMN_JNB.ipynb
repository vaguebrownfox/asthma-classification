{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "mic_data = pd.read_csv(\"./withoutCMN-12X53mic.csv\")\n",
    "mic_data_cmn = pd.read_csv(\"./withCMN-12X53mic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate folds - #7\n",
    "def fold(sound_dataframe, sets_loc):\n",
    "    big = []\n",
    "    for j in os.listdir(sets_loc):\n",
    "\n",
    "        file = open(sets_loc+j, 'r') \n",
    "        Lines = file.readlines() \n",
    "\n",
    "        count = 0\n",
    "        try:\n",
    "            set_dataframe = pd.DataFrame()\n",
    "            for i, line in enumerate(Lines):\n",
    "                A = sound_dataframe[(sound_dataframe['73'] == (Lines[i].strip()+\".json\"))]\n",
    "                set_dataframe = pd.DataFrame.append(set_dataframe,A)\n",
    "        except:\n",
    "            set_dataframe = pd.DataFrame()\n",
    "            for i, line in enumerate(Lines):\n",
    "                A = sound_dataframe[(sound_dataframe[73] == (Lines[i].strip()+\".json\"))]\n",
    "                set_dataframe = pd.DataFrame.append(set_dataframe,A)\n",
    "            \n",
    "        \n",
    "        big.append(set_dataframe)\n",
    "    fold_1 = shuffle(pd.concat(big[:6]))\n",
    "    test_1 = shuffle(big[6])\n",
    "    fold_2 = shuffle(pd.concat(big[1:7]))\n",
    "    test_2 = shuffle(big[0])\n",
    "    fold_3 = shuffle(pd.concat([big[0],big[2],big[3],big[4], big[5], big[6]]))\n",
    "    test_3 = shuffle(big[1])\n",
    "    fold_4 = shuffle(pd.concat([big[0],big[1],big[3],big[4], big[5], big[6]]))\n",
    "    test_4 = shuffle(big[2])\n",
    "    fold_5 = shuffle(pd.concat([big[0],big[2],big[1],big[4], big[5], big[6]]))\n",
    "    test_5 = shuffle(big[3])\n",
    "    fold_6 = shuffle(pd.concat([big[0],big[2],big[1],big[3], big[5], big[6]]))\n",
    "    test_6 = shuffle(big[4])\n",
    "    fold_7 = shuffle(pd.concat([big[0],big[2],big[1],big[4], big[3], big[6]]))\n",
    "    test_7 = shuffle(big[5])\n",
    "    \n",
    "    return [fold_1,test_1,fold_2,test_2,fold_3,test_3,fold_4,test_4,fold_5,test_5, fold_6, test_6, fold_7,test_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_path = './Sets/'\n",
    "mic_fold_list = fold(mic_data, sets_path)\n",
    "mic_cmn_fold_list = fold(mic_data_cmn, sets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def xgb_classifier(train_test_folds) :\n",
    "    \n",
    "    xgb_accuracy_test = []\n",
    "    xgb_accuracy_train = []\n",
    "    \n",
    "    for i in range(0,len(train_test_folds), 2):\n",
    "        fold_train = train_test_folds[i]\n",
    "        fold_test = train_test_folds[i + 1]\n",
    "        \n",
    "        X = fold_train.iloc[:, :-2]\n",
    "        y = fold_train.iloc[:, -2]\n",
    "        \n",
    "        X_test = fold_test.iloc[:, :-2]\n",
    "        y_test = fold_test.iloc[:, -2]\n",
    "        \n",
    "        classifier_xgb = XGBClassifier()\n",
    "        classifier_xgb.fit(X, y)\n",
    "        y_pred = classifier_xgb.predict(X_test)\n",
    "        \n",
    "        a_test = accuracy_score(y_test, y_pred)\n",
    "        xgb_accuracy_test.append(a_test)\n",
    "        a_train = accuracy_score(y,classifier_xgb.predict(X))\n",
    "        xgb_accuracy_train.append(a_train)\n",
    "        \n",
    "    mean_accuracy_xgb = {\"test_mean_accuracy\": np.mean(xgb_accuracy_test), \n",
    "                         \"train_mean_accuracy\": np.mean(xgb_accuracy_train)}\n",
    "    \n",
    "    return mean_accuracy_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def svm_classifier(train_test_folds):\n",
    "    \n",
    "    svm_accuracy_test = []\n",
    "    svm_accuracy_train = []\n",
    "    \n",
    "    for i in range(0,len(train_test_folds),2):\n",
    "        fold_train = train_test_folds[i]\n",
    "        fold_test = train_test_folds[i + 1]\n",
    "        \n",
    "        X = fold_train.iloc[:, :-2]\n",
    "        y = fold_train.iloc[:, -2]\n",
    "        \n",
    "        X_test = fold_test.iloc[:, :-2]\n",
    "        y_test = fold_test.iloc[:, -2]\n",
    "\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        X = pd.DataFrame(X)\n",
    "        X_test = pd.DataFrame(X_test)\n",
    "\n",
    "        classifier_svm = SVC()\n",
    "        classifier_svm.fit(X, y)\n",
    "        y_pred = classifier_svm.predict(X_test)\n",
    "\n",
    "\n",
    "        a_test = accuracy_score(y_test, y_pred)\n",
    "        svm_accuracy_test.append(a_test)\n",
    "        a_train = accuracy_score(y, classifier_svm.predict(X))\n",
    "        svm_accuracy_train.append(a_train)\n",
    "        \n",
    "    mean_accuracy_svm = {\"test_mean_accuracy\": np.mean(svm_accuracy_test), \n",
    "                         \"train_mean_accuracy\": np.mean(svm_accuracy_train)}\n",
    "    \n",
    "    return mean_accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    res = {\"mic\": {\"xgb\": xgb_classifier(mic_fold_list), \"svm\": svm_classifier(mic_fold_list)},\n",
    "         \"mic_cmn\": {\"xgb\": xgb_classifier(mic_cmn_fold_list), \"svm\": svm_classifier(mic_cmn_fold_list)}}\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:09:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "e = evaluate()\n",
    "result = pd.DataFrame.from_dict(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mic': {'xgb': {'test_mean_accuracy': 0.5343203588458041,\n",
       "   'train_mean_accuracy': 1.0},\n",
       "  'svm': {'test_mean_accuracy': 0.5663351613086542,\n",
       "   'train_mean_accuracy': 0.9449121169623388}},\n",
       " 'mic_cmn': {'xgb': {'test_mean_accuracy': 0.568942138036183,\n",
       "   'train_mean_accuracy': 1.0},\n",
       "  'svm': {'test_mean_accuracy': 0.5583423751707991,\n",
       "   'train_mean_accuracy': 0.9465287442352481}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
